{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('/home/yurui/GDSC_2/code')\n",
    "from code.model.drp_model.DRP_multi_conc import *\n",
    "from code.loader.GDSC2_loader import *\n",
    "import warnings\n",
    "import argparse\n",
    "import datetime\n",
    "import torch.cuda.amp as amp\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "import torch.optim as opt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "def arg_parse():\n",
    "    parser = argparse.ArgumentParser(description=\"Model Configuration\")\n",
    "    parser.add_argument('--drug_embed_dim', type=int, default=256,\n",
    "                        help='Embedding dimension for drug')\n",
    "    parser.add_argument('--cell_embed_dim', type=int, default=128,\n",
    "                        help='Embedding dimension for cell')\n",
    "    parser.add_argument('--drug_layer_num', type=int, default=2,\n",
    "                        help='Number of layers for drug')\n",
    "    parser.add_argument('--cell_layer_num', type=int, default=2,\n",
    "                        help='Number of layers for cell')\n",
    "    parser.add_argument('--dropout_rate', type=float, default=0.3,\n",
    "                        help='Dropout rate')\n",
    "    parser.add_argument('--readout', type=str, default='mean',\n",
    "                        help='Readout function')\n",
    "    parser.add_argument('--JK', type=str, default='True',\n",
    "                        help='JKNet option')\n",
    "    parser.add_argument('--view_dim', type=int, default=256)\n",
    "    parser.add_argument('--epochs', type=int, default=50)    \n",
    "    parser.add_argument('--lr', type= float, default = 1e-3,\n",
    "                        help='Learning rate')\n",
    "    parser.add_argument('--batch_size', type=int, default= 1024,\n",
    "                        help='Batch size')\n",
    "    # parser.add_argument('--device', type = str, default = 0,\n",
    "    #                     help='Device')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.01, \n",
    "                        help='Weight decay')\n",
    "    parser.add_argument('--check_step', type=int, default = 5,\n",
    "                        help='Num of steps to check performance')\n",
    "    parser.add_argument('--use_regulizer', type=str, default='True')\n",
    "    parser.add_argument('--regular_weight', type=float, default= 0.1)\n",
    "    parser.add_argument('--use_drug_path_way', type=str, default='True')\n",
    "    parser.add_argument('--regular_weight_drug_path_way', type=float, default= 0.1)\n",
    "    parser.add_argument('--train_type', type=str, default='Mixed')\n",
    "    parser.add_argument('--scheduler_type', type=str, default='OP')\n",
    "    parser.add_argument('--device',type = int, default= 0)\n",
    "    parser.add_argument('--early_stop_count',type = int, default= 7)\n",
    "    return parser.parse_args('')\n",
    "def cross_entropy_loss(input, target):\n",
    "    return F.cross_entropy(input, target)\n",
    "def total_loss(out_dict, batch_sample, args):\n",
    "    m = args.regular_weight\n",
    "    p = args.regular_weight_drug_path_way\n",
    "    mse_loss_fn = nn.MSELoss()\n",
    "    pred_loss = 0\n",
    "    for i in range(out_dict['pred'].shape[1]):  # Assuming the second dimension represents the columns\n",
    "        pred_loss += (i + 1)*mse_loss_fn(out_dict['pred'][:, i], batch_sample['label'][:, i])\n",
    "    class_l = 0.0\n",
    "    drug_pathway_l = 0.0\n",
    "    if args.use_regulizer == 'True':\n",
    "        class_l = cross_entropy_loss(out_dict['cell_regulizer'], batch_sample['CL_type'])\n",
    "    if args.use_drug_path_way == 'True':\n",
    "        drug_pathway_l = cross_entropy_loss(out_dict['drug_pathway'], batch_sample['drug_atom_repr'].PATHWAY_TYPE)\n",
    "    return pred_loss + m * class_l + p*drug_pathway_l\n",
    "def train_step(model, train_loader, optimizer, writer, epoch, device, args):\n",
    "    # enable automatic mixed precision\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    model.train()\n",
    "    y_true, preds = [], []\n",
    "    optimizer.zero_grad()\n",
    "    for data in tqdm(train_loader):\n",
    "        batch_sample = {k: v.to(device) for k, v in data.items()}              \n",
    "        with amp.autocast():\n",
    "            out_dict = model(batch_sample)\n",
    "            loss = total_loss(out_dict, batch_sample, args)\n",
    "        preds.append(out_dict['pred'].float())\n",
    "        y_true.append(batch_sample['label'])\n",
    "        # perform backward pass and optimizer step using the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        # scheduler.step()\n",
    "    y_true = torch.cat(y_true, dim=0).cpu().detach().numpy()\n",
    "    y_pred = torch.cat(preds, dim=0).cpu().detach().numpy()\n",
    "    rmse_dict = {}\n",
    "    pcc_dict = {}\n",
    "    r2_dict = {}\n",
    "    MAE_dict = {}\n",
    "    for i in range(7):\n",
    "        column_true = y_true[:, i]\n",
    "        column_pred = y_pred[:, i]\n",
    "        rmse = mean_squared_error(column_true, column_pred, squared=False)\n",
    "        rmse_dict[i] = rmse\n",
    "        pcc = pearsonr(column_true, column_pred)[0]\n",
    "        pcc_dict[i] = pcc\n",
    "        r_2 = r2_score(column_true, column_pred)\n",
    "        r2_dict[i] = r_2\n",
    "        MAE = mean_absolute_error(column_true, column_pred)\n",
    "        MAE_dict[i] = MAE\n",
    "        # print(f'Train accuracy for dose {i}: RMSE: {rmse:.4f}, PCC: {pcc:.4f}, R2: {r_2:.4f}, MAE: {MAE:.4f}')\n",
    "        writer.add_scalar(\"Loss\", rmse, epoch)\n",
    "        writer.add_scalar(f\"Accuracy/train/response_for_conc_{i+1}/rmse\", rmse, epoch)\n",
    "        writer.add_scalar(f\"Accuracy/train/response_for_conc_{i+1}/mae\", MAE, epoch)\n",
    "        writer.add_scalar(f\"Accuracy/train/response_for_conc_{i+1}/pcc\", pcc, epoch)\n",
    "        writer.add_scalar(f\"Accuracy/train/response_for_conc_{i+1}/r_2\", r_2, epoch)\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    return rmse_dict, pcc_dict\n",
    "@torch.no_grad()\n",
    "def test_step(model,loader,device):\n",
    "    model.eval()\n",
    "    y_true, preds = [], []\n",
    "    for data in tqdm(loader):\n",
    "        batch_sample = {k: v.to(device) for k, v in data.items()}   \n",
    "        out_dict = model(batch_sample)\n",
    "        y_true.append(batch_sample['label'])\n",
    "        preds.append(out_dict['pred'].float().cpu())\n",
    "    y_true = torch.cat(y_true, dim=0).cpu().detach()\n",
    "    y_pred = torch.cat(preds, dim=0).cpu().detach()\n",
    "    test_rmse = nn.MSELoss()(y_true, y_pred)\n",
    "    y_true = y_true.numpy()\n",
    "    y_pred = y_pred.numpy()\n",
    "    rmse_dict = {}\n",
    "    pcc_dict = {}\n",
    "    r2_dict = {}\n",
    "    MAE_dict = {}\n",
    "    for i in range(7):\n",
    "        column_true = y_true[:, i]\n",
    "        column_pred = y_pred[:, i]\n",
    "        rmse = mean_squared_error(column_true, column_pred, squared=False)\n",
    "        rmse_dict[i] = rmse\n",
    "        pcc = pearsonr(column_true, column_pred)[0]\n",
    "        pcc_dict[i] = pcc\n",
    "        r_2 = r2_score(column_true, column_pred)\n",
    "        r2_dict[i] = r_2\n",
    "        MAE = mean_absolute_error(column_true, column_pred)\n",
    "        MAE_dict[i] = MAE\n",
    "        print(f'Test accuracy for dose {i}: RMSE: {rmse:.4f}, PCC: {pcc:.4f}, R2: {r_2:.4f}, MAE: {MAE:.4f}')\n",
    "    return rmse_dict, pcc_dict, r2_dict, MAE_dict, test_rmse\n",
    "\n",
    "def train_multi_view_model(args, train_set, val_set, test_set):\n",
    "    save_dir = 'best_model_' + args.train_type\n",
    "    lr = args.lr\n",
    "    device = torch.device(f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu')\n",
    "    batch_size = args.batch_size\n",
    "    drug_embed_dim = args.drug_embed_dim\n",
    "    dropout_rate = args.dropout_rate\n",
    "    drug_layer_num = args.drug_layer_num   \n",
    "    readout = args.readout ## mean, max\n",
    "    JK = args.JK ## 'True', 'False', string value\n",
    "    ## Config for cells\n",
    "    cell_embed_dim = args.cell_embed_dim\n",
    "    cell_layer_num = args.cell_layer_num\n",
    "    ## Config for genes\n",
    "    view_dim = args.view_dim   \n",
    "    n_epochs = args.epochs \n",
    "    use_regulizer = args.use_regulizer\n",
    "    use_drug_path_way = args.use_drug_path_way\n",
    "    model_config = {'drug_embed_dim': drug_embed_dim,\n",
    "                    'cell_embed_dim': cell_embed_dim, \n",
    "                    'hidden_dim': cell_embed_dim, \n",
    "                    'drug_layer_num': drug_layer_num, ## This is for drug\n",
    "                    'cell_layer_num': cell_layer_num, ## This is for cell\n",
    "                    'dropout_rate' : dropout_rate,\n",
    "                    'readout': readout,\n",
    "                    'JK': JK,\n",
    "                    'view_dim': view_dim,\n",
    "                    'use_regulizer': use_regulizer,\n",
    "                    'use_drug_path_way': use_drug_path_way\n",
    "                    }  \n",
    "    path = f'./TB_5_fold/{save_dir}'+'.pth' \n",
    "    model = DRP_multi_view(model_config).to(device)\n",
    "    # model = torch.compile(model)\n",
    "    optimizer = opt.AdamW(model.parameters(), lr=lr, weight_decay= 0.01)\n",
    "        # scheduler = get_polynomial_decay_schedule_with_warmup(optimizer,num_warmup_steps=50, num_training_steps=n_epochs, lr_end = 1e-4, power=1)\n",
    "    # elif optimizer_name == 'SGD': \n",
    "        # optimizer = opt.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-2)\n",
    "    # cos_lr = lambda x : ((1+math.cos(math.pi* x /100) )/2)*(1-args.lrf) + args.lrf\n",
    "    # scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=cos_lr)\n",
    "    current_time = datetime.datetime.now().time()\n",
    "    print('Begin Training')\n",
    "    print(f'Embed_dim_drug : {drug_embed_dim}'+ '\\n' +f'Hidden_dim_cell : {cell_embed_dim} \\n' +  f'drug_layer_num : {drug_layer_num} \\n'+ \n",
    "            f'read_out_function : {readout}\\n'  +f'batch_size : {batch_size}\\n' + f'view_dim : {view_dim}\\n' + \n",
    "            f'lr : {lr}\\n' + f'use_regulizer : {use_regulizer}\\n' + f'use_drug_path_way : {use_drug_path_way}')\n",
    "    tb = SummaryWriter(comment=current_time, log_dir=f'./TB_5_fold/{save_dir}')\n",
    "    train_loader = DataLoader(train_set, batch_size= batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_set, batch_size= batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_set, batch_size= batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    epoch_len = len(str(n_epochs))\n",
    "    results = 'model_results'\n",
    "    if os.path.exists(f\"./{results}/{args.train_type}\") is False:\n",
    "        os.makedirs(f\"./{results}/{args.train_type}\")\n",
    "    early_stop_count = 0 \n",
    "    best_epoch = 0 \n",
    "    best_val_rmse = 100\n",
    "    if args.scheduler_type == 'OP':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience= 7 , verbose=True, min_lr= 0.05 * args.lr, factor= 0.1)\n",
    "    elif args.scheduler_type == 'ML':\n",
    "        scheduler = opt.lr_scheduler.MultiStepLR(optimizer, milestones=[80], gamma=0.1)\n",
    "    for epoch in range(n_epochs):\n",
    "        if early_stop_count < args.early_stop_count :\n",
    "            train_rmse, train_pcc = train_step(model, train_loader, optimizer, tb, epoch, device, args)\n",
    "            if args.scheduler_type == 'ML':\n",
    "                scheduler.step()\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            for i in range(7):\n",
    "                print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] '  + \n",
    "                            f'train_rmse for conc {i}: {train_rmse[i]:.5f} ' +\n",
    "                            f'train_pcc for conc {i}: {train_pcc[i]:.5f} ' +  f'lr : {current_lr}')\n",
    "                print(print_msg)\n",
    "            if epoch % args.check_step == 0:\n",
    "                val_rmse,val_pcc, val_r_2, val_mae, val_threshold_rmse = test_step(model, val_loader, device)\n",
    "                if args.scheduler_type == 'OP':\n",
    "                    scheduler.step(val_threshold_rmse)\n",
    "                for i in range(7):\n",
    "                    tb.add_scalar(f'Accuracy/val/pcc_conc_{i}', val_pcc[i], epoch)\n",
    "                    tb.add_scalar(f\"Accuracy/val/rmse_conc_{i}\", val_rmse[i], epoch)\n",
    "                    tb.add_scalar(f\"Accuracy/val/mae_conc_{i}\", val_mae[i], epoch)\n",
    "                    tb.add_scalar(f\"Accuracy/val/r_2_conc_{i}\", val_r_2[i], epoch)\n",
    "                    tb.add_scalar(\"LR\", optimizer.param_groups[0]['lr'], epoch)\n",
    "                    print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] '  + \n",
    "                                f'val_rmse for conc {i}: {val_rmse[i]:.5f} ' +\n",
    "                                f'val_r_2 for conc {i}: {val_r_2[i]:.5f} ' +\n",
    "                                f'val_mae for conc {i}: {val_mae[i]:.5f} ' +\n",
    "                                f'val_pcc for conc {i}: {val_pcc[i]:.5f} ' +  f'lr : {current_lr}')\n",
    "                    print(print_msg)\n",
    "                if val_threshold_rmse < best_val_rmse:\n",
    "                    early_stop_count = 0\n",
    "                    best_val_rmse = val_threshold_rmse\n",
    "                    best_epoch = epoch\n",
    "                    test_rmse, test_pcc, test_r_2, test_mae, test_threshold_rmse = test_step(model,test_loader, device)\n",
    "                    torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict' : optimizer.state_dict(),\n",
    "                            }, path)\n",
    "                else: \n",
    "                    early_stop_count += 1 \n",
    "                    print(f'Early stopping encounter : {early_stop_count}  times')\n",
    "                if early_stop_count >= args.early_stop_count:\n",
    "                    print('Early stopping!')\n",
    "                    break\n",
    "                print(f'Best epoch: {best_epoch:03d}')\n",
    "                for i in range(7):\n",
    "                    print(f'Best PCC for conc {i}: {test_pcc[i]:.4f},'\n",
    "                        f'Best RMSE for conc {i}: {test_rmse[i]:.4f}, '\n",
    "                        f'Best R_2 for conc {i}: {test_r_2[i]:.4f}, '\n",
    "                        f'Best MAE for conc {i}: {test_mae[i]:.4f}')\n",
    "\n",
    "    print(\"__________________________________________________________\")\n",
    "    hparams = {\n",
    "        'use_regulizer': use_regulizer,\n",
    "        'use_drug_path_way': use_drug_path_way,\n",
    "        'best_epoch': best_epoch,\n",
    "        'regular_weight': args.regular_weight,\n",
    "        'regular_weight_drug_path_way': args.regular_weight_drug_path_way\n",
    "    }\n",
    "\n",
    "    metrics = {\n",
    "        'val_threshold_rmse': best_val_rmse,\n",
    "        'test_threshold_rmse': test_threshold_rmse\n",
    "    }\n",
    "\n",
    "    # Add metrics for each concentration\n",
    "    for i in range(7):\n",
    "        metrics[f'test_pcc_conc_{i}'] = test_pcc[i]\n",
    "        metrics[f'test_rmse_conc_{i}'] = test_rmse[i]\n",
    "        metrics[f'test_r2_conc_{i}'] = test_r_2[i]\n",
    "        metrics[f'test_mae_conc_{i}'] = test_mae[i]\n",
    "    tb.add_hparams(hparams, metrics)\n",
    "    tb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading drug data!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = arg_parse()\n",
    "device = torch.device(\"cuda:\"+str(args.device) if torch.cuda.is_available() else \"cpu\") \n",
    "mut_tensor, chr_tensor, cna_tensor, GE_tensor, CL_type_tensor, label_tensor, result_df, drug2index, CL2index = preprocess_cell_data()\n",
    "drug_atom_feat, drug_bond_feat = process_drug_feat(drug2index)\n",
    "train_idx, val_idx, test_idx = train_val_test_split(result_df)\n",
    "drug_train_idx, CL_train_idx = process_CL_drug(train_idx)\n",
    "drug_val_idx, CL_val_idx = process_CL_drug(val_idx)\n",
    "drug_test_idx, CL_test_idx = process_CL_drug(test_idx)\n",
    "DRP_trainset = DRP_dataset(mut_tensor, chr_tensor, cna_tensor, GE_tensor, CL_type_tensor, drug_atom_feat, drug_bond_feat, result_tensor=label_tensor, drug_idx = drug_train_idx, CL_idx = CL_train_idx)\n",
    "DRP_valset = DRP_dataset(mut_tensor, chr_tensor, cna_tensor, GE_tensor, CL_type_tensor, drug_atom_feat, drug_bond_feat, result_tensor=label_tensor, drug_idx = drug_val_idx, CL_idx = CL_val_idx)\n",
    "DRP_testset = DRP_dataset(mut_tensor, chr_tensor, cna_tensor, GE_tensor, CL_type_tensor, drug_atom_feat, drug_bond_feat, result_tensor=label_tensor, drug_idx = drug_test_idx, CL_idx = CL_test_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training\n",
      "Embed_dim_drug : 256\n",
      "Hidden_dim_cell : 128 \n",
      "drug_layer_num : 2 \n",
      "read_out_function : mean\n",
      "batch_size : 1024\n",
      "view_dim : 256\n",
      "lr : 0.001\n",
      "use_regulizer : True\n",
      "use_drug_path_way : True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:06<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[ 0/50] train_rmse for conc 0: 0.81480 train_pcc for conc 0: -0.00819 lr : 0.001\n",
      "[ 0/50] train_rmse for conc 1: 0.91794 train_pcc for conc 1: -0.00252 lr : 0.001\n",
      "[ 0/50] train_rmse for conc 2: 0.90960 train_pcc for conc 2: -0.00981 lr : 0.001\n",
      "[ 0/50] train_rmse for conc 3: 0.93007 train_pcc for conc 3: -0.00386 lr : 0.001\n",
      "[ 0/50] train_rmse for conc 4: 0.96326 train_pcc for conc 4: -0.00243 lr : 0.001\n",
      "[ 0/50] train_rmse for conc 5: 0.94786 train_pcc for conc 5: -0.00012 lr : 0.001\n",
      "[ 0/50] train_rmse for conc 6: 0.91533 train_pcc for conc 6: 0.00134 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:22<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for dose 0: RMSE: 0.3972, PCC: -0.0000, R2: -25.9746, MAE: 0.3496\n",
      "Test accuracy for dose 1: RMSE: 0.5125, PCC: -0.0058, R2: -35.0932, MAE: 0.4903\n",
      "Test accuracy for dose 2: RMSE: 0.3950, PCC: -0.0029, R2: -10.7478, MAE: 0.3605\n",
      "Test accuracy for dose 3: RMSE: 0.2745, PCC: -0.0021, R2: -1.7820, MAE: 0.2360\n",
      "Test accuracy for dose 4: RMSE: 0.4836, PCC: 0.0005, R2: -3.8249, MAE: 0.4179\n",
      "Test accuracy for dose 5: RMSE: 0.5544, PCC: 0.0008, R2: -3.2872, MAE: 0.4891\n",
      "Test accuracy for dose 6: RMSE: 0.4586, PCC: 0.0041, R2: -1.3688, MAE: 0.4003\n",
      "[ 0/50] val_rmse for conc 0: 0.39717 val_r_2 for conc 0: -25.97464 val_mae for conc 0: 0.34961 val_pcc for conc 0: -0.00004 lr : 0.001\n",
      "[ 0/50] val_rmse for conc 1: 0.51251 val_r_2 for conc 1: -35.09322 val_mae for conc 1: 0.49033 val_pcc for conc 1: -0.00578 lr : 0.001\n",
      "[ 0/50] val_rmse for conc 2: 0.39501 val_r_2 for conc 2: -10.74778 val_mae for conc 2: 0.36053 val_pcc for conc 2: -0.00292 lr : 0.001\n",
      "[ 0/50] val_rmse for conc 3: 0.27446 val_r_2 for conc 3: -1.78197 val_mae for conc 3: 0.23596 val_pcc for conc 3: -0.00208 lr : 0.001\n",
      "[ 0/50] val_rmse for conc 4: 0.48360 val_r_2 for conc 4: -3.82485 val_mae for conc 4: 0.41790 val_pcc for conc 4: 0.00046 lr : 0.001\n",
      "[ 0/50] val_rmse for conc 5: 0.55444 val_r_2 for conc 5: -3.28723 val_mae for conc 5: 0.48905 val_pcc for conc 5: 0.00082 lr : 0.001\n",
      "[ 0/50] val_rmse for conc 6: 0.45860 val_r_2 for conc 6: -1.36876 val_mae for conc 6: 0.40030 val_pcc for conc 6: 0.00407 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:07<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for dose 0: RMSE: 0.3982, PCC: 0.0015, R2: -29.1503, MAE: 0.3515\n",
      "Test accuracy for dose 1: RMSE: 0.5184, PCC: 0.0089, R2: -43.7664, MAE: 0.4971\n",
      "Test accuracy for dose 2: RMSE: 0.4005, PCC: -0.0021, R2: -12.4423, MAE: 0.3667\n",
      "Test accuracy for dose 3: RMSE: 0.2775, PCC: 0.0072, R2: -1.9091, MAE: 0.2411\n",
      "Test accuracy for dose 4: RMSE: 0.4860, PCC: -0.0046, R2: -3.7022, MAE: 0.4205\n",
      "Test accuracy for dose 5: RMSE: 0.5504, PCC: 0.0016, R2: -2.8758, MAE: 0.4829\n",
      "Test accuracy for dose 6: RMSE: 0.4538, PCC: -0.0078, R2: -1.0902, MAE: 0.3933\n",
      "Best epoch: 000\n",
      "Best PCC for conc 0: 0.0015,Best RMSE for conc 0: 0.3982, Best R_2 for conc 0: -29.1503, Best MAE for conc 0: 0.3515\n",
      "Best PCC for conc 1: 0.0089,Best RMSE for conc 1: 0.5184, Best R_2 for conc 1: -43.7664, Best MAE for conc 1: 0.4971\n",
      "Best PCC for conc 2: -0.0021,Best RMSE for conc 2: 0.4005, Best R_2 for conc 2: -12.4423, Best MAE for conc 2: 0.3667\n",
      "Best PCC for conc 3: 0.0072,Best RMSE for conc 3: 0.2775, Best R_2 for conc 3: -1.9091, Best MAE for conc 3: 0.2411\n",
      "Best PCC for conc 4: -0.0046,Best RMSE for conc 4: 0.4860, Best R_2 for conc 4: -3.7022, Best MAE for conc 4: 0.4205\n",
      "Best PCC for conc 5: 0.0016,Best RMSE for conc 5: 0.5504, Best R_2 for conc 5: -2.8758, Best MAE for conc 5: 0.4829\n",
      "Best PCC for conc 6: -0.0078,Best RMSE for conc 6: 0.4538, Best R_2 for conc 6: -1.0902, Best MAE for conc 6: 0.3933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:07<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[ 1/50] train_rmse for conc 0: 0.34972 train_pcc for conc 0: 0.00548 lr : 0.001\n",
      "[ 1/50] train_rmse for conc 1: 0.25281 train_pcc for conc 1: 0.00002 lr : 0.001\n",
      "[ 1/50] train_rmse for conc 2: 0.27992 train_pcc for conc 2: 0.00410 lr : 0.001\n",
      "[ 1/50] train_rmse for conc 3: 0.30419 train_pcc for conc 3: -0.00150 lr : 0.001\n",
      "[ 1/50] train_rmse for conc 4: 0.35235 train_pcc for conc 4: 0.00043 lr : 0.001\n",
      "[ 1/50] train_rmse for conc 5: 0.40041 train_pcc for conc 5: -0.00825 lr : 0.001\n",
      "[ 1/50] train_rmse for conc 6: 0.38963 train_pcc for conc 6: -0.00127 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:06<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[ 2/50] train_rmse for conc 0: 0.19652 train_pcc for conc 0: 0.00444 lr : 0.001\n",
      "[ 2/50] train_rmse for conc 1: 0.18537 train_pcc for conc 1: 0.00471 lr : 0.001\n",
      "[ 2/50] train_rmse for conc 2: 0.19010 train_pcc for conc 2: -0.00597 lr : 0.001\n",
      "[ 2/50] train_rmse for conc 3: 0.22032 train_pcc for conc 3: 0.01318 lr : 0.001\n",
      "[ 2/50] train_rmse for conc 4: 0.27179 train_pcc for conc 4: 0.00817 lr : 0.001\n",
      "[ 2/50] train_rmse for conc 5: 0.32389 train_pcc for conc 5: 0.01137 lr : 0.001\n",
      "[ 2/50] train_rmse for conc 6: 0.35332 train_pcc for conc 6: 0.01330 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:06<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[ 3/50] train_rmse for conc 0: 0.15507 train_pcc for conc 0: -0.00037 lr : 0.001\n",
      "[ 3/50] train_rmse for conc 1: 0.14814 train_pcc for conc 1: 0.01191 lr : 0.001\n",
      "[ 3/50] train_rmse for conc 2: 0.15983 train_pcc for conc 2: 0.01306 lr : 0.001\n",
      "[ 3/50] train_rmse for conc 3: 0.20266 train_pcc for conc 3: 0.00858 lr : 0.001\n",
      "[ 3/50] train_rmse for conc 4: 0.25858 train_pcc for conc 4: 0.00851 lr : 0.001\n",
      "[ 3/50] train_rmse for conc 5: 0.31132 train_pcc for conc 5: 0.00419 lr : 0.001\n",
      "[ 3/50] train_rmse for conc 6: 0.34059 train_pcc for conc 6: 0.01216 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:07<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[ 4/50] train_rmse for conc 0: 0.14135 train_pcc for conc 0: -0.00464 lr : 0.001\n",
      "[ 4/50] train_rmse for conc 1: 0.14194 train_pcc for conc 1: 0.00340 lr : 0.001\n",
      "[ 4/50] train_rmse for conc 2: 0.15346 train_pcc for conc 2: 0.00725 lr : 0.001\n",
      "[ 4/50] train_rmse for conc 3: 0.19852 train_pcc for conc 3: -0.00155 lr : 0.001\n",
      "[ 4/50] train_rmse for conc 4: 0.25457 train_pcc for conc 4: 0.01049 lr : 0.001\n",
      "[ 4/50] train_rmse for conc 5: 0.30871 train_pcc for conc 5: 0.01082 lr : 0.001\n",
      "[ 4/50] train_rmse for conc 6: 0.33752 train_pcc for conc 6: 0.01397 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:07<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[ 5/50] train_rmse for conc 0: 0.13177 train_pcc for conc 0: 0.00702 lr : 0.001\n",
      "[ 5/50] train_rmse for conc 1: 0.13410 train_pcc for conc 1: 0.00647 lr : 0.001\n",
      "[ 5/50] train_rmse for conc 2: 0.14876 train_pcc for conc 2: -0.00040 lr : 0.001\n",
      "[ 5/50] train_rmse for conc 3: 0.19491 train_pcc for conc 3: 0.00714 lr : 0.001\n",
      "[ 5/50] train_rmse for conc 4: 0.25341 train_pcc for conc 4: 0.00739 lr : 0.001\n",
      "[ 5/50] train_rmse for conc 5: 0.30723 train_pcc for conc 5: 0.00909 lr : 0.001\n",
      "[ 5/50] train_rmse for conc 6: 0.33640 train_pcc for conc 6: 0.00988 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:22<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for dose 0: RMSE: 0.0853, PCC: -0.0044, R2: -0.2436, MAE: 0.0626\n",
      "Test accuracy for dose 1: RMSE: 0.0995, PCC: -0.0033, R2: -0.3607, MAE: 0.0707\n",
      "Test accuracy for dose 2: RMSE: 0.1311, PCC: -0.0003, R2: -0.2949, MAE: 0.0867\n",
      "Test accuracy for dose 3: RMSE: 0.1752, PCC: -0.0006, R2: -0.1331, MAE: 0.1149\n",
      "Test accuracy for dose 4: RMSE: 0.2255, PCC: -0.0010, R2: -0.0494, MAE: 0.1699\n",
      "Test accuracy for dose 5: RMSE: 0.2754, PCC: 0.0007, R2: -0.0578, MAE: 0.2283\n",
      "Test accuracy for dose 6: RMSE: 0.3037, PCC: -0.0020, R2: -0.0385, MAE: 0.2590\n",
      "[ 5/50] val_rmse for conc 0: 0.08528 val_r_2 for conc 0: -0.24359 val_mae for conc 0: 0.06257 val_pcc for conc 0: -0.00444 lr : 0.001\n",
      "[ 5/50] val_rmse for conc 1: 0.09951 val_r_2 for conc 1: -0.36070 val_mae for conc 1: 0.07073 val_pcc for conc 1: -0.00329 lr : 0.001\n",
      "[ 5/50] val_rmse for conc 2: 0.13115 val_r_2 for conc 2: -0.29494 val_mae for conc 2: 0.08667 val_pcc for conc 2: -0.00032 lr : 0.001\n",
      "[ 5/50] val_rmse for conc 3: 0.17517 val_r_2 for conc 3: -0.13312 val_mae for conc 3: 0.11486 val_pcc for conc 3: -0.00063 lr : 0.001\n",
      "[ 5/50] val_rmse for conc 4: 0.22554 val_r_2 for conc 4: -0.04939 val_mae for conc 4: 0.16987 val_pcc for conc 4: -0.00104 lr : 0.001\n",
      "[ 5/50] val_rmse for conc 5: 0.27540 val_r_2 for conc 5: -0.05778 val_mae for conc 5: 0.22834 val_pcc for conc 5: 0.00068 lr : 0.001\n",
      "[ 5/50] val_rmse for conc 6: 0.30365 val_r_2 for conc 6: -0.03848 val_mae for conc 6: 0.25901 val_pcc for conc 6: -0.00200 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:06<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for dose 0: RMSE: 0.0814, PCC: 0.0003, R2: -0.2591, MAE: 0.0609\n",
      "Test accuracy for dose 1: RMSE: 0.0922, PCC: 0.0060, R2: -0.4160, MAE: 0.0671\n",
      "Test accuracy for dose 2: RMSE: 0.1246, PCC: 0.0018, R2: -0.3012, MAE: 0.0829\n",
      "Test accuracy for dose 3: RMSE: 0.1724, PCC: 0.0049, R2: -0.1220, MAE: 0.1136\n",
      "Test accuracy for dose 4: RMSE: 0.2293, PCC: 0.0012, R2: -0.0467, MAE: 0.1729\n",
      "Test accuracy for dose 5: RMSE: 0.2863, PCC: -0.0004, R2: -0.0486, MAE: 0.2375\n",
      "Test accuracy for dose 6: RMSE: 0.3190, PCC: 0.0017, R2: -0.0325, MAE: 0.2734\n",
      "Best epoch: 005\n",
      "Best PCC for conc 0: 0.0003,Best RMSE for conc 0: 0.0814, Best R_2 for conc 0: -0.2591, Best MAE for conc 0: 0.0609\n",
      "Best PCC for conc 1: 0.0060,Best RMSE for conc 1: 0.0922, Best R_2 for conc 1: -0.4160, Best MAE for conc 1: 0.0671\n",
      "Best PCC for conc 2: 0.0018,Best RMSE for conc 2: 0.1246, Best R_2 for conc 2: -0.3012, Best MAE for conc 2: 0.0829\n",
      "Best PCC for conc 3: 0.0049,Best RMSE for conc 3: 0.1724, Best R_2 for conc 3: -0.1220, Best MAE for conc 3: 0.1136\n",
      "Best PCC for conc 4: 0.0012,Best RMSE for conc 4: 0.2293, Best R_2 for conc 4: -0.0467, Best MAE for conc 4: 0.1729\n",
      "Best PCC for conc 5: -0.0004,Best RMSE for conc 5: 0.2863, Best R_2 for conc 5: -0.0486, Best MAE for conc 5: 0.2375\n",
      "Best PCC for conc 6: 0.0017,Best RMSE for conc 6: 0.3190, Best R_2 for conc 6: -0.0325, Best MAE for conc 6: 0.2734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:06<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[ 6/50] train_rmse for conc 0: 0.12796 train_pcc for conc 0: 0.01513 lr : 0.001\n",
      "[ 6/50] train_rmse for conc 1: 0.13062 train_pcc for conc 1: 0.00086 lr : 0.001\n",
      "[ 6/50] train_rmse for conc 2: 0.14764 train_pcc for conc 2: -0.00355 lr : 0.001\n",
      "[ 6/50] train_rmse for conc 3: 0.19340 train_pcc for conc 3: -0.00398 lr : 0.001\n",
      "[ 6/50] train_rmse for conc 4: 0.25210 train_pcc for conc 4: 0.00777 lr : 0.001\n",
      "[ 6/50] train_rmse for conc 5: 0.30661 train_pcc for conc 5: 0.00313 lr : 0.001\n",
      "[ 6/50] train_rmse for conc 6: 0.33411 train_pcc for conc 6: 0.01330 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:06<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[ 7/50] train_rmse for conc 0: 0.12485 train_pcc for conc 0: -0.00631 lr : 0.001\n",
      "[ 7/50] train_rmse for conc 1: 0.12767 train_pcc for conc 1: -0.00838 lr : 0.001\n",
      "[ 7/50] train_rmse for conc 2: 0.14304 train_pcc for conc 2: -0.00537 lr : 0.001\n",
      "[ 7/50] train_rmse for conc 3: 0.19058 train_pcc for conc 3: -0.00056 lr : 0.001\n",
      "[ 7/50] train_rmse for conc 4: 0.24967 train_pcc for conc 4: 0.00765 lr : 0.001\n",
      "[ 7/50] train_rmse for conc 5: 0.30495 train_pcc for conc 5: 0.01076 lr : 0.001\n",
      "[ 7/50] train_rmse for conc 6: 0.33437 train_pcc for conc 6: 0.01005 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:06<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[ 8/50] train_rmse for conc 0: 0.12049 train_pcc for conc 0: 0.00049 lr : 0.001\n",
      "[ 8/50] train_rmse for conc 1: 0.13076 train_pcc for conc 1: -0.00055 lr : 0.001\n",
      "[ 8/50] train_rmse for conc 2: 0.14939 train_pcc for conc 2: 0.01019 lr : 0.001\n",
      "[ 8/50] train_rmse for conc 3: 0.19136 train_pcc for conc 3: 0.00889 lr : 0.001\n",
      "[ 8/50] train_rmse for conc 4: 0.24986 train_pcc for conc 4: 0.01549 lr : 0.001\n",
      "[ 8/50] train_rmse for conc 5: 0.30556 train_pcc for conc 5: 0.01283 lr : 0.001\n",
      "[ 8/50] train_rmse for conc 6: 0.33312 train_pcc for conc 6: 0.02409 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:07<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[ 9/50] train_rmse for conc 0: 0.11777 train_pcc for conc 0: 0.00815 lr : 0.001\n",
      "[ 9/50] train_rmse for conc 1: 0.12553 train_pcc for conc 1: 0.00916 lr : 0.001\n",
      "[ 9/50] train_rmse for conc 2: 0.14081 train_pcc for conc 2: -0.00638 lr : 0.001\n",
      "[ 9/50] train_rmse for conc 3: 0.18850 train_pcc for conc 3: 0.00249 lr : 0.001\n",
      "[ 9/50] train_rmse for conc 4: 0.24802 train_pcc for conc 4: 0.01352 lr : 0.001\n",
      "[ 9/50] train_rmse for conc 5: 0.30375 train_pcc for conc 5: 0.00995 lr : 0.001\n",
      "[ 9/50] train_rmse for conc 6: 0.33311 train_pcc for conc 6: 0.00478 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:07<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[10/50] train_rmse for conc 0: 0.11526 train_pcc for conc 0: -0.00355 lr : 0.001\n",
      "[10/50] train_rmse for conc 1: 0.12359 train_pcc for conc 1: -0.00060 lr : 0.001\n",
      "[10/50] train_rmse for conc 2: 0.14078 train_pcc for conc 2: 0.00086 lr : 0.001\n",
      "[10/50] train_rmse for conc 3: 0.18913 train_pcc for conc 3: 0.01241 lr : 0.001\n",
      "[10/50] train_rmse for conc 4: 0.24788 train_pcc for conc 4: 0.01133 lr : 0.001\n",
      "[10/50] train_rmse for conc 5: 0.30340 train_pcc for conc 5: 0.01273 lr : 0.001\n",
      "[10/50] train_rmse for conc 6: 0.33197 train_pcc for conc 6: 0.01850 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:22<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for dose 0: RMSE: 0.0857, PCC: 0.0011, R2: -0.2567, MAE: 0.0676\n",
      "Test accuracy for dose 1: RMSE: 0.0923, PCC: -0.0058, R2: -0.1718, MAE: 0.0653\n",
      "Test accuracy for dose 2: RMSE: 0.1231, PCC: -0.0039, R2: -0.1400, MAE: 0.0796\n",
      "Test accuracy for dose 3: RMSE: 0.1690, PCC: 0.0036, R2: -0.0550, MAE: 0.1105\n",
      "Test accuracy for dose 4: RMSE: 0.2245, PCC: -0.0004, R2: -0.0396, MAE: 0.1698\n",
      "Test accuracy for dose 5: RMSE: 0.2710, PCC: -0.0012, R2: -0.0245, MAE: 0.2214\n",
      "Test accuracy for dose 6: RMSE: 0.3029, PCC: -0.0020, R2: -0.0332, MAE: 0.2539\n",
      "[10/50] val_rmse for conc 0: 0.08573 val_r_2 for conc 0: -0.25665 val_mae for conc 0: 0.06755 val_pcc for conc 0: 0.00112 lr : 0.001\n",
      "[10/50] val_rmse for conc 1: 0.09235 val_r_2 for conc 1: -0.17180 val_mae for conc 1: 0.06533 val_pcc for conc 1: -0.00584 lr : 0.001\n",
      "[10/50] val_rmse for conc 2: 0.12305 val_r_2 for conc 2: -0.14005 val_mae for conc 2: 0.07959 val_pcc for conc 2: -0.00388 lr : 0.001\n",
      "[10/50] val_rmse for conc 3: 0.16902 val_r_2 for conc 3: -0.05500 val_mae for conc 3: 0.11052 val_pcc for conc 3: 0.00363 lr : 0.001\n",
      "[10/50] val_rmse for conc 4: 0.22448 val_r_2 for conc 4: -0.03960 val_mae for conc 4: 0.16976 val_pcc for conc 4: -0.00038 lr : 0.001\n",
      "[10/50] val_rmse for conc 5: 0.27102 val_r_2 for conc 5: -0.02445 val_mae for conc 5: 0.22143 val_pcc for conc 5: -0.00124 lr : 0.001\n",
      "[10/50] val_rmse for conc 6: 0.30288 val_r_2 for conc 6: -0.03323 val_mae for conc 6: 0.25390 val_pcc for conc 6: -0.00201 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:06<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for dose 0: RMSE: 0.0830, PCC: -0.0032, R2: -0.3091, MAE: 0.0669\n",
      "Test accuracy for dose 1: RMSE: 0.0853, PCC: -0.0044, R2: -0.2129, MAE: 0.0624\n",
      "Test accuracy for dose 2: RMSE: 0.1169, PCC: -0.0036, R2: -0.1447, MAE: 0.0764\n",
      "Test accuracy for dose 3: RMSE: 0.1669, PCC: -0.0018, R2: -0.0522, MAE: 0.1107\n",
      "Test accuracy for dose 4: RMSE: 0.2286, PCC: -0.0060, R2: -0.0404, MAE: 0.1728\n",
      "Test accuracy for dose 5: RMSE: 0.2830, PCC: -0.0055, R2: -0.0244, MAE: 0.2315\n",
      "Test accuracy for dose 6: RMSE: 0.3203, PCC: 0.0020, R2: -0.0414, MAE: 0.2697\n",
      "Best epoch: 010\n",
      "Best PCC for conc 0: -0.0032,Best RMSE for conc 0: 0.0830, Best R_2 for conc 0: -0.3091, Best MAE for conc 0: 0.0669\n",
      "Best PCC for conc 1: -0.0044,Best RMSE for conc 1: 0.0853, Best R_2 for conc 1: -0.2129, Best MAE for conc 1: 0.0624\n",
      "Best PCC for conc 2: -0.0036,Best RMSE for conc 2: 0.1169, Best R_2 for conc 2: -0.1447, Best MAE for conc 2: 0.0764\n",
      "Best PCC for conc 3: -0.0018,Best RMSE for conc 3: 0.1669, Best R_2 for conc 3: -0.0522, Best MAE for conc 3: 0.1107\n",
      "Best PCC for conc 4: -0.0060,Best RMSE for conc 4: 0.2286, Best R_2 for conc 4: -0.0404, Best MAE for conc 4: 0.1728\n",
      "Best PCC for conc 5: -0.0055,Best RMSE for conc 5: 0.2830, Best R_2 for conc 5: -0.0244, Best MAE for conc 5: 0.2315\n",
      "Best PCC for conc 6: 0.0020,Best RMSE for conc 6: 0.3203, Best R_2 for conc 6: -0.0414, Best MAE for conc 6: 0.2697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:06<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[11/50] train_rmse for conc 0: 0.11259 train_pcc for conc 0: -0.00928 lr : 0.001\n",
      "[11/50] train_rmse for conc 1: 0.12023 train_pcc for conc 1: -0.00182 lr : 0.001\n",
      "[11/50] train_rmse for conc 2: 0.13539 train_pcc for conc 2: 0.00035 lr : 0.001\n",
      "[11/50] train_rmse for conc 3: 0.18482 train_pcc for conc 3: 0.01763 lr : 0.001\n",
      "[11/50] train_rmse for conc 4: 0.24601 train_pcc for conc 4: 0.02151 lr : 0.001\n",
      "[11/50] train_rmse for conc 5: 0.30201 train_pcc for conc 5: 0.01451 lr : 0.001\n",
      "[11/50] train_rmse for conc 6: 0.33103 train_pcc for conc 6: 0.01809 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:07<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[12/50] train_rmse for conc 0: 0.10776 train_pcc for conc 0: 0.01281 lr : 0.001\n",
      "[12/50] train_rmse for conc 1: 0.11571 train_pcc for conc 1: 0.01269 lr : 0.001\n",
      "[12/50] train_rmse for conc 2: 0.13453 train_pcc for conc 2: 0.00213 lr : 0.001\n",
      "[12/50] train_rmse for conc 3: 0.18404 train_pcc for conc 3: 0.01717 lr : 0.001\n",
      "[12/50] train_rmse for conc 4: 0.24592 train_pcc for conc 4: 0.01569 lr : 0.001\n",
      "[12/50] train_rmse for conc 5: 0.30115 train_pcc for conc 5: 0.02418 lr : 0.001\n",
      "[12/50] train_rmse for conc 6: 0.33054 train_pcc for conc 6: 0.01807 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:07<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[13/50] train_rmse for conc 0: 0.10937 train_pcc for conc 0: 0.00191 lr : 0.001\n",
      "[13/50] train_rmse for conc 1: 0.11842 train_pcc for conc 1: 0.00778 lr : 0.001\n",
      "[13/50] train_rmse for conc 2: 0.13565 train_pcc for conc 2: 0.00105 lr : 0.001\n",
      "[13/50] train_rmse for conc 3: 0.18461 train_pcc for conc 3: 0.01207 lr : 0.001\n",
      "[13/50] train_rmse for conc 4: 0.24604 train_pcc for conc 4: 0.01363 lr : 0.001\n",
      "[13/50] train_rmse for conc 5: 0.30224 train_pcc for conc 5: 0.01084 lr : 0.001\n",
      "[13/50] train_rmse for conc 6: 0.33086 train_pcc for conc 6: 0.01133 lr : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 6/23 [00:02<00:07,  2.40it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/yurui/GDSC_2/train_multi_output.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_multi_view_model(args, train_set \u001b[39m=\u001b[39;49m DRP_trainset, val_set \u001b[39m=\u001b[39;49m DRP_valset, test_set \u001b[39m=\u001b[39;49m DRP_testset)\n",
      "\u001b[1;32m/home/yurui/GDSC_2/train_multi_output.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=204'>205</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=205'>206</a>\u001b[0m     \u001b[39mif\u001b[39;00m early_stop_count \u001b[39m<\u001b[39m args\u001b[39m.\u001b[39mearly_stop_count :\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=206'>207</a>\u001b[0m         train_rmse, train_pcc \u001b[39m=\u001b[39m train_step(model, train_loader, optimizer, tb, epoch, device, args)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=207'>208</a>\u001b[0m         \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mscheduler_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mML\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=208'>209</a>\u001b[0m             scheduler\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32m/home/yurui/GDSC_2/train_multi_output.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39m# perform backward pass and optimizer step using the scaler\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m scaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m scaler\u001b[39m.\u001b[39;49mstep(optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m scaler\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256656761227d/home/yurui/GDSC_2/train_multi_output.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/drug_response_env/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:370\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    368\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 370\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_opt_step(optimizer, optimizer_state, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    372\u001b[0m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mstage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m OptState\u001b[39m.\u001b[39mSTEPPED\n\u001b[1;32m    374\u001b[0m \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/drug_response_env/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:290\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39msum\u001b[39m(v\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m--> 290\u001b[0m     retval \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49mstep(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    291\u001b[0m \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/envs/drug_response_env/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/drug_response_env/lib/python3.9/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/drug_response_env/lib/python3.9/site-packages/torch/optim/adamw.py:171\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    158\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    161\u001b[0m         group,\n\u001b[1;32m    162\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m         state_steps,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m     adamw(\n\u001b[1;32m    172\u001b[0m         params_with_grad,\n\u001b[1;32m    173\u001b[0m         grads,\n\u001b[1;32m    174\u001b[0m         exp_avgs,\n\u001b[1;32m    175\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    176\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    177\u001b[0m         state_steps,\n\u001b[1;32m    178\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    179\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    180\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    181\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    182\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    183\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    184\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    185\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    186\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    187\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    188\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    189\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    190\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/drug_response_env/lib/python3.9/site-packages/torch/optim/adamw.py:321\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 321\u001b[0m func(\n\u001b[1;32m    322\u001b[0m     params,\n\u001b[1;32m    323\u001b[0m     grads,\n\u001b[1;32m    324\u001b[0m     exp_avgs,\n\u001b[1;32m    325\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    326\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    327\u001b[0m     state_steps,\n\u001b[1;32m    328\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    329\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    330\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    331\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    332\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    333\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    334\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    335\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    336\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    337\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    338\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[1;32m    339\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/drug_response_env/lib/python3.9/site-packages/torch/optim/adamw.py:485\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mif\u001b[39;00m maximize:\n\u001b[1;32m    482\u001b[0m     device_grads \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_foreach_neg(\u001b[39mtuple\u001b[39m(device_grads))  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m device_grads \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mview_as_real(x) \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(x) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_grads]\n\u001b[1;32m    486\u001b[0m device_exp_avgs \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mview_as_real(x) \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(x) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_exp_avgs]\n\u001b[1;32m    487\u001b[0m device_exp_avg_sqs \u001b[39m=\u001b[39m [\n\u001b[1;32m    488\u001b[0m     torch\u001b[39m.\u001b[39mview_as_real(x) \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(x) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_exp_avg_sqs\n\u001b[1;32m    489\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/drug_response_env/lib/python3.9/site-packages/torch/optim/adamw.py:485\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mif\u001b[39;00m maximize:\n\u001b[1;32m    482\u001b[0m     device_grads \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_foreach_neg(\u001b[39mtuple\u001b[39m(device_grads))  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m device_grads \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mview_as_real(x) \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49mis_complex(x) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_grads]\n\u001b[1;32m    486\u001b[0m device_exp_avgs \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mview_as_real(x) \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(x) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_exp_avgs]\n\u001b[1;32m    487\u001b[0m device_exp_avg_sqs \u001b[39m=\u001b[39m [\n\u001b[1;32m    488\u001b[0m     torch\u001b[39m.\u001b[39mview_as_real(x) \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(x) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_exp_avg_sqs\n\u001b[1;32m    489\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_multi_view_model(args, train_set = DRP_trainset, val_set = DRP_valset, test_set = DRP_testset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drug_response_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
